https://ollama.com/download
https://gpt-oss.com/
http://localhost:11434/

Ollama is running

ðŸ“Œ Mejor opciÃ³n para EC2 Free Tier (t2.micro, t3.micro):

tinyllama (modelo: tinyllama)
TamaÃ±o: ~1.1 GB

Velocidad: Muy rÃ¡pido en CPU.

Uso: Ideal para tareas bÃ¡sicas de conversaciÃ³n.

Soporte en Ollama: âœ… Disponible y ligero.

Prompt contextual: Acepta contexto corto (ideal si el mensaje del cliente y tu respuesta son breves).

ðŸš€ CÃ³mo iniciar en Ollama:

```sh
curl -fsSL https://ollama.com/install.sh | sh

ollama run tinyllama

ollama run gpt-oss:20b
```
